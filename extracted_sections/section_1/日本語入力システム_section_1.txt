b プロジェクト名：ニューラル言語モデルによる個人最適な日本語入力システムの開発  申請者名：三輪敬太、高橋直希  【提案プロジェクト詳細】  1   なにをつくるか  本提案書では「ニューラル言語モデルによる個人最適な日本語入力システムの開発」を主目標とし、ハイエンド  のデスクトップ環境を対象として、新たな日本語入力システムの開発を提案する。これにより、多様なユーザの  ための快適な日本語入力を開発し、公開する。  1.1   背景  日本語入力は 1 億人を超える日本語話者がデジタル化社会で生活する上で、なくてはならないシステムである。  我々は、現状の日本語入力の問題点として次の 3 点を指摘したい。  ●   変換精度  ●   個人最適化  ●   予測入力  以下にその背景を述べる。  ■ 変換精度   日本語入力には今なお十分に解決されていない精度の問題があり、不正確な候補への変換を優  先することがある。多くのかな漢字変換システムは現在でも 2-gram や 3-gram などの単純な言語モデルに基づ  いており、長距離の依存関係を考慮することが難しい。また、新語や流行語、俗語への対応が遅く、これらの言  葉が入力できないことも多い。  ■ 個人最適化   一方、ユーザの持つ不満の多くは単なる精度の問題ではなく、パーソナライズをはじめとする広  義の「文脈」理解への不満である。趣味、嗜好、年齢、職業、居住地などのプロフィール的情報や、「今どこにい  るか」「なんのサイトを見ているのか」「最近読んだ漫画は何か」などのユーザの状況など、システムが推薦すべ  きテキストは広い意味での「文脈」に依存する。従来のシステムはユーザ文脈の理解をシステムへのフィード  バックにのみ頼っており、こうした個人最適化が不十分である。  ■ 予測入力   近年は「予測変換」への不満の声もよく聞かれるようになった。この背景として、 ChatGPT をはじめ  とする文章生成 AI の普及がある。メールや説明文など、創造性の問われない文章を作成する際には、日本語入  力システムが生成 AI のように文章を自動生成し、入力を支援するのが望ましい。しかし現実の日本語入力シス  テムは履歴に含まれる文や、入力途中の単語を予測変換する程度である。句や文、文章を予測入力するシステ  ムは未だに実現されていない。  1.2   提案プロジェクト  1
提案プロジェクトでは、ユーザの広範な文脈情報を組み合わせ、高度に最適化した変換や予測入力を実現する  日本語入力システムを開発する。このシステムは主に、ニューラル言語モデルの利点を活かしたかな漢字変換  システムと、ユーザの文脈を記録するデータベースシステムからなる。  かな漢字変換システムとしてニューラル言語モデルを用いたアルゴリズムを提案する。このアルゴリズムは、数  百語に及ぶ長いテキストを考慮することができ、従来の n-gram 言語モデルベースのアルゴリズムと比べて「補  償」と「保証」のような文脈依存の同音異義語における精度を向上させる。また、辞書データへの依存度が低い  ため、新語や流行語への対応にかかるメンテナンスコストを削減できるほか、個人最適化の観点でもメリットが  ある。実用のため、かな漢字変換のパフォーマンスを重視し、高速化・省メモリ化の方法も併せて提案する。  次に、ユーザの「文脈」を記録するデータベースシステムを提案アルゴリズムと組み合わせることで、ユーザに最  適化した変換と高精度な予測入力を実現する。変換に用いるニューラル言語モデルは、このデータベースを用  いて定期的にローカル環境でファインチューニングされ、高度な個人最適化を可能にする。また、ファインチュー  ニングでカバーしきれない短期間の文脈は文書検索の手法を用いて考慮に入れる。  最後に、提案する個人最適化に基づき、ユーザへの深い理解に基づいた予測入力システムを実現する。従来  のシステムはユーザ理解に乏しいため弱い予測しかできなかったが、提案システムでは文単位の予測を含む高  度な予測入力を実現する。  以上のとおり、提案プロジェクトは従来の日本語入力の課題である「変換精度」「個人最適化」「予測入力」の問  題を解決し、新世代の日本語入力システムを実現する。以下に詳細を述べる。  1.2.1   ニューラル言語モデルを用いたかな漢字変換アルゴリズム  1.2.1.1   目的  すでに述べたものも含め、ニューラル言語モデルを用いたかな漢字変換には複数の利点がある。これらの利点  は我々の実現したい柔軟な個人最適化の上で不可欠である。  ●   長距離の文脈を正確に考慮することで、既存システムで誤変換を生じるケースをカバーできる  ●   ニューラル言語モデル自体をファインチューニングすることで、個人最適化をシンプルな形で、かつ効果  的に実現できる（プロトタイプも参照）  ●   多くの属性を持った辞書を明示的に利用しなくて良いため、開発プロセスがシンプルになる  一方で、日本語入力システムとニューラル言語モデルを組み合わせる方法には検討の必要がある。まず、従来  の日本語入力では読みや頻度、品詞の属性を持った単語の辞書をベースとした手法が一般的だが、ニューラル  言語モデルはこのような情報を明示的に持っていないため、既存のアルゴリズムが適用できない。また、予備実  験として様々な事前学習モデルを用いて「タスクの説明 → 例題 → 問題」という構成（ few-shot learning ）によるか  な漢字変換を行わせたところ、 GPT-4 を除いて入力に忠実な変換が全く出来ないことがわかった。 ChatGPT-3 が  入力に忠実な変換に失敗する例では「ようしょうき」を「要証紙（ようしょうし）」と変換してしまっている。 この振る舞いは言  語モデルがそもそも日本語の読みに関する情報をほとんど学習できていないことに由来すると考えられるが、本  プロジェクトで実装するシステムではこの忠実性の問題を解決する必要がある。  1.2.1.2   アルゴリズム  高精度なニューラル言語モデルを活かした変換を実現するため、ニューラル言語モデルの利用を前提とした新  規のかな漢字変換アルゴリズムを提案する。従来システム、 few-shot learning によるシステム、提案システムの  違いを表にまとめた。  提案手法では、次トークン予測を繰り返しながら文を生成するビームサーチのような手法を、適切な追加制約  （読み制約）に基づいて利用することでかな漢字変換を実現する。  ■ 精度   ニューラル言語モデルが意味関係を詳細に考慮できることから、大幅な改善が得られる。後述のプロト  タイプでは既存の変換器に比べた性能向上を確認した。  2  通常のシステム  (n-gram)  ニューラル言語モデル  +few-shot  ニューラル言語モデル  + 提案手法  精度   🔺 局所的な文脈活用   ⭕ 長距離の文脈活用   ⭕ 長距離の文脈活用  効率   ⭕ 高速で省メモリ   ❌ 低速でメモリ消費大   ⭕ 投機的 decoding と量子化で改善  忠実性   ⭕ 辞書利用で忠実   ❌ 入力を無視   ⭕ 読み制約で担保  学習   🔺 履歴ベース   🔺 プロンプトで制御   ⭕ 文脈データベースに基づき個人最適化
■ 効率   次節 1.2.1.3 で詳しく議論する。  ■ 忠実性   これを担保するため、読みによる制約を用いる。例えば「紙」を「き」とは読まないことから、「ようしょう  き」に対して「 要証紙 」との変換が不適切であることを検出し、生成を防止する。従来のシステムは単語単位に基  づいたシステムであり、「ようしょうき → 幼少期 」のような対応関係を示す辞書データから変換していたが、我々の  システムはこれを「よう → 幼 」「しょう → 少 」「き → 期」と漢字 1 文字単位で与える。単語単位は探索する状態数を減  らす上で効率的であり、文字単位では「よう → 幼 」「しょう → 賞 」のような通常起こり得ない熟語を検討する必要が  発生してしまう。しかし、ニューラル言語モデルとビームサーチにより、これを効率的に避けることができる。  ■ 学習   既存の辞書ベース手法は単語単位を利用するが、こうした手法では「ふかぼる → 深掘る」などの新語へ  の対応が困難である。これでは個人最適化の観点で必要な柔軟性を実現できない。また、読みと単語の対応関  係の保証も簡単ではなく 1 、辞書データのメンテナンスが難しい。提案アルゴリズムは漢字 1 文字単位の読み制  約を基本とした緩い制約のみを用いることで、こうした柔軟性を確保する。  このような形で、シンプルなニューラル言語モデルを利用しつつもかな漢字変換エンジンとして実用可能なシス  テムを構築する。  1.2.1.3   省メモリ化・高速化  日本語入力は重要だが、他のアプリケーションと共用する補助的なシステムである。このため、システムのリ  ソースを過剰に消費してはならない。我々は省メモリ化と高速化の両面からシステムの効率化を図る。  省メモリ化については、言語モデルの量子化により言語モデルのメモリ消費を抑える。プロトタイプ（後述）では  GPT-2 モデルに対して llama.cpp による量子化を適用し、単純な生成時のメモリ消費を 150MB 程度に抑えた。こ  れは Apple の「日本語入力プログラム」の 200MB 程度よりも小さい。  高速化については、投機的デコーディングと呼ばれる手法を採用する。これは高速で低精度な方法で先読みし  て候補の生成を行い、高精度で大きな言語モデルによってその妥当性を検証しながら生成を進める高速化手法  である。先読み候補が一致した場合に高速化が得られる。かな漢字変換では、最長一致法のようなシンプルな  アルゴリズムでもある程度の精度が得られることが知られているため、このような高速で低精度のヒューリスティ  クスを先読みに用いることで、大幅な高速化が期待できる。  1.2.2   「文脈」のデータベースシステム  1.2.2.1. データベースの構築  上記のニューラルかな漢字変換システムとともに高度な個人最適化を実現するために、我々は「文脈」のデータ  ベースシステムを開発する。これはユーザ自身が自身のプロフィールや、過去に書いたテキスト、ブラウザの閲  覧履歴、画面上に表示されたテキストなど、最適化に有用と考えられる情報を任意で提供し、それを日本語入力  のために効率的な形で記録するシステムである。  具体的には、以下のような情報をデータベース化する。  ■ ユーザのプロフィール   ニューラル言語モデルはプロンプトによって挙動を大きく変えることができる。そこで  ユーザのプロフィールをプロンプトに含めながら先述の変換アルゴリズムを利用することで、低コストの個人最適  化を実現できる。  ■ ユーザが書いたテキスト   多くの場合、ユーザは SNS やチャット、メモアプリなど、様々な場面ですでに多くのテ  キストを生産している。これらをユーザが任意でシステムに与えることで、過去のユーザのテキストに基づいて  ニューラル言語モデルをファインチューニングすることができる。  ■ ユーザが読んだテキスト   多くのユーザは全くの造語ではなく、過去に自身が読んだテキストから引用する形  で、新しい言葉を使う。 SNS で「雷雪」という珍しい気象現象を知り、それについて言及する、というような振る舞  いはその例になる。これらのテキストを日本語入力システムが知ることができれば、さらに高度な文脈の把握が  可能になり、それに基づいた変換も可能となる。ユーザがこのようなテキストデータをシ...